{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'process_ekman_data' from '/home/xiaoyuz1/emotion-infused/process_ekman_data.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import process_ekman_data as ped\n",
    "from importlib import reload\n",
    "reload(ped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GoEmotions\n",
    "\n",
    "go_f = \"/raid/xiaoyuz1/goemotions/goemotions/data/dev_ekman.csv\"\n",
    "par_dirs = \"/raid/xiaoyuz1/goemotions/goemotions/data/goemotions\"\n",
    "\n",
    "for div in [\"train\", \"dev\", \"test\"]:\n",
    "    go_f = \"/raid/xiaoyuz1/goemotions/goemotions/data/{}_ekman.csv\".format(div)\n",
    "    par_dir = os.path.join(\"/raid/xiaoyuz1/goemotions/goemotions/data/goemotions\", div)\n",
    "    for e in [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"neutral\"]:\n",
    "        df = ped.read_goemotions(go_f, e)\n",
    "        save_dir = os.path.join(par_dir, \"{}.csv\".format(e))\n",
    "        df.to_csv(save_dir, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "------------------------------------NEW DATASET--------------------------------------------------------\n",
    "'''\n",
    "# AffectiveText\n",
    "# id anger disgust fear joy sadness surprise\n",
    "# label: 0 1 2 3 4 5\n",
    "\n",
    "tweet_f1 = \"/raid/xiaoyuz1/goemotions/AffectiveText.Semeval.2007/AffectiveText.test/affectivetext_test.xml\"\n",
    "emotion_f1 = \\\n",
    "    \"/raid/xiaoyuz1/goemotions/AffectiveText.Semeval.2007/AffectiveText.test/affectivetext_test.emotions.gold\"\n",
    "tweet_f2 = \\\n",
    "    \"/raid/xiaoyuz1/goemotions/AffectiveText.Semeval.2007/AffectiveText.trial/affectivetext_trial.xml\"\n",
    "emotion_f2 = \\\n",
    "    \"/raid/xiaoyuz1/goemotions/AffectiveText.Semeval.2007/AffectiveText.trial/affectivetext_trial.emotions.gold\"\n",
    "\n",
    "par_dir = \"/raid/xiaoyuz1/goemotions/goemotions/data/affectivetext\"\n",
    "\n",
    "for e in [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"neutral\"]:\n",
    "    save_dir = os.path.join(par_dir, \"{}.csv\".format(e))\n",
    "    df1 = ped.read1([tweet_f1, tweet_f2], [emotion_f1, emotion_f2], e)\n",
    "    df1.to_csv(save_dir, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "------------------------------------NEW DATASET--------------------------------------------------------\n",
    "'''\n",
    "# /raid/xiaoyuz1/goemotions/WASSA-2017\n",
    "# http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html\n",
    "\n",
    "par_dir = \"/raid/xiaoyuz1/goemotions/WASSA-2017\"\n",
    "paths = [os.path.join(par_dir, p) for p in os.listdir(par_dir)]\n",
    "\n",
    "par_dir_new = \"/raid/xiaoyuz1/goemotions/goemotions/data/wassa2017\"\n",
    "\n",
    "for e in [\"sadness\", \"fear\", \"anger\", \"joy\", \"neutral\"]:\n",
    "    df = ped.read2(paths, e)\n",
    "    path_dir = os.path.join(par_dir_new, \"{}.csv\".format(e))\n",
    "    df.to_csv(path_dir, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "------------------------------------NEW DATASET--------------------------------------------------------\n",
    "'''\n",
    "data_dir = \"/raid/xiaoyuz1/goemotions/SemEval2018-Task1-all-data/English/E-c\"\n",
    "par_dir_new = \"/raid/xiaoyuz1/goemotions/goemotions/data/semeval2018_c\"\n",
    "\n",
    "for e in [\"anger\", \"fear\", \"joy\", \"sadness\", \"disgust\", \"surprise\"]:\n",
    "    paths = []\n",
    "    for a in os.listdir(data_dir):\n",
    "        if not a.split(\".\")[1] == \"txt\":\n",
    "            continue\n",
    "            \n",
    "        path = os.path.join(data_dir, a)\n",
    "        paths.append(path)\n",
    "        \n",
    "#     print(e, paths)\n",
    "    new_path = os.path.join(par_dir_new, \"{}.csv\".format(e))\n",
    "    df = ped.read3(paths, e)\n",
    "    df.to_csv(new_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "------------------------------------NEW DATASET--------------------------------------------------------\n",
    "'''\n",
    "\n",
    "data_dir = \"/raid/xiaoyuz1/goemotions/SemEval2018-Task1-all-data/English/EI-reg\"\n",
    "par_dir_new = \"/raid/xiaoyuz1/goemotions/goemotions/data/semeval2018\"\n",
    "\n",
    "for e in [\"anger\", \"fear\", \"joy\", \"sadness\"]:\n",
    "    paths = []\n",
    "    for a in os.listdir(data_dir):\n",
    "        sub_dir = os.path.join(data_dir, a)\n",
    "\n",
    "        for b in os.listdir(sub_dir):\n",
    "            path = os.path.join(sub_dir, b)\n",
    "#             if not e in path:\n",
    "#                 continue\n",
    "            \n",
    "            paths.append(path)\n",
    "#     print(e, paths)\n",
    "    new_path = os.path.join(par_dir_new, \"{}.csv\".format(e))\n",
    "    df = ped.read4(paths, e)\n",
    "    df.to_csv(new_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "------------------------------------NEW DATASET--------------------------------------------------------\n",
    "'''\n",
    "# Daily Dialog\n",
    "text_file = \"/raid/xiaoyuz1/goemotions/DailyDialog/dialogues_text.txt\"\n",
    "emotion_file = \"/raid/xiaoyuz1/goemotions/DailyDialog/dialogues_emotion.txt\"\n",
    "\n",
    "par_dir_new = \"/raid/xiaoyuz1/goemotions/goemotions/data/dailydialog\"\n",
    "\n",
    "for e in [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]:\n",
    "    df = ped.read5(text_file, emotion_file, e)\n",
    "    new_path = os.path.join(par_dir_new, \"{}.csv\".format(e))\n",
    "    df.to_csv(new_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "------------------------------------NEW DATASET--------------------------------------------------------\n",
    "'''\n",
    "df1 = ped.read6(\"/raid/xiaoyuz1/goemotions/GroundedEmotions/collected_data/collected_tweets.txt\", \"sad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.to_csv(\"/raid/xiaoyuz1/goemotions/goemotions/data/groundedemotion/sadness.csv\", index=False)\n",
    "df2 = ped.read6(\"/raid/xiaoyuz1/goemotions/GroundedEmotions/collected_data/collected_tweets.txt\", \"happy\")\n",
    "df2.to_csv(\"/raid/xiaoyuz1/goemotions/goemotions/data/groundedemotion/joy.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "------------------------------------NEW DATASET--------------------------------------------------------\n",
    "'''\n",
    "path = \"/raid/xiaoyuz1/goemotions/EmotionStimulus/Emotion Cause.txt\"\n",
    "emos = [\"happy\", \"sad\", \"anger\", \"fear\", \"surprise\", \"disgust\"]\n",
    "mapped_e = [\"joy\", \"sadness\", \"anger\", \"fear\", \"surprise\", \"disgust\"]\n",
    "\n",
    "par_dir_new = \"/raid/xiaoyuz1/goemotions/goemotions/data/emotionstimulus\"\n",
    "\n",
    "for e1,e2 in zip(emos, mapped_e):\n",
    "    df = ped.read7(path, e1)\n",
    "    new_path = os.path.join(par_dir_new, \"{}.csv\".format(e2))\n",
    "    df.to_csv(new_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/raid/xiaoyuz1/goemotions/EmotionStimulus/No Cause.txt\"\n",
    "emos = [\"happy\", \"sad\", \"anger\", \"fear\", \"surprise\", \"disgust\"]\n",
    "mapped_e = [\"joy\", \"sadness\", \"anger\", \"fear\", \"surprise\", \"disgust\"]\n",
    "\n",
    "par_dir_new = \"/raid/xiaoyuz1/goemotions/goemotions/data/emotionstimulus_2\"\n",
    "\n",
    "for e1,e2 in zip(emos, mapped_e):\n",
    "    df = ped.read7(path, e1)\n",
    "    new_path = os.path.join(par_dir_new, \"{}.csv\".format(e2))\n",
    "    df.to_csv(new_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "------------------------------------NEW DATASET--------------------------------------------------------\n",
    "'''\n",
    "emos = ['neutral', 'surprise', 'fear', 'sadness', 'joy', 'disgust', 'anger']\n",
    "paths = [\n",
    "    \"/raid/xiaoyuz1/goemotions/MELD/train_sent_emo.csv\",\n",
    "    \"/raid/xiaoyuz1/goemotions/MELD/dev_sent_emo.csv\",\n",
    "    \"/raid/xiaoyuz1/goemotions/MELD/test_sent_emo.csv\",\n",
    "]\n",
    "\n",
    "par_dir_new = \"/raid/xiaoyuz1/goemotions/goemotions/data/friends\"\n",
    "\n",
    "\n",
    "for e in emos:\n",
    "    df = ped.read8(paths, e)\n",
    "    new_path = os.path.join(par_dir_new, \"{}.csv\".format(e))\n",
    "    df.to_csv(new_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "------------------------------------NEW DATASET--------------------------------------------------------\n",
    "'''\n",
    "\n",
    "emos = ['surprise', 'fear', 'sadness', 'joy', 'disgust', 'anger']\n",
    "par_dir_new = \"/raid/xiaoyuz1/goemotions/goemotions/data/tectweet\"\n",
    "path = \"/raid/xiaoyuz1/goemotions/Jan9-2012-tweets-clean.txt\"\n",
    "\n",
    "for e in emos:\n",
    "    df = ped.read9(path, e)\n",
    "    new_path = os.path.join(par_dir_new, \"{}.csv\".format(e))\n",
    "    df.to_csv(new_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = \"sadness\"\n",
    "\n",
    "paths_templates = [\n",
    "    '/raid/xiaoyuz1/goemotions/goemotions/data/affectivetext/{}.csv',\n",
    "    '/raid/xiaoyuz1/goemotions/goemotions/data/wassa2017/{}.csv',\n",
    "    '/raid/xiaoyuz1/goemotions/goemotions/data/semeval2018/{}.csv',\n",
    "    '/raid/xiaoyuz1/goemotions/goemotions/data/semeval2018_c/{}.csv',\n",
    "    '/raid/xiaoyuz1/goemotions/goemotions/data/dailydialog/{}.csv',\n",
    "    '/raid/xiaoyuz1/goemotions/goemotions/data/groundedemotion/{}.csv',\n",
    "    '/raid/xiaoyuz1/goemotions/goemotions/data/emotionstimulus/{}.csv',\n",
    "    '/raid/xiaoyuz1/goemotions/goemotions/data/emotionstimulus_2/{}.csv',\n",
    "    '/raid/xiaoyuz1/goemotions/goemotions/data/friends/{}.csv',\n",
    "    '/raid/xiaoyuz1/goemotions/goemotions/data/tectweet/{}.csv',\n",
    "]\n",
    "\n",
    "paths = [p.format(e) for p in paths_templates]\n",
    "df = ped.merge(paths)\n",
    "df.to_csv(\"/raid/xiaoyuz1/goemotions/goemotions/data/ekman/{}/train.csv\".format(e), index=False)\n",
    "\n",
    "paths = [\n",
    "    '/raid/xiaoyuz1/goemotions/goemotions/data/goemotions/dev/{}.csv'.format(e),\n",
    "]\n",
    "df = ped.merge(paths)\n",
    "df.to_csv(\"/raid/xiaoyuz1/goemotions/goemotions/data/ekman/{}/dev.csv\".format(e), index=False)\n",
    "\n",
    "\n",
    "paths = [\n",
    "    '/raid/xiaoyuz1/goemotions/goemotions/data/goemotions/test/{}.csv'.format(e),\n",
    "]\n",
    "df = ped.merge(paths)\n",
    "df.to_csv(\"/raid/xiaoyuz1/goemotions/goemotions/data/ekman/{}/test.csv\".format(e), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy.csv  sadness.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls /raid/xiaoyuz1/goemotions/goemotions/data/groundedemotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/raid/xiaoyuz1/goemotions/goemotions/data/ekman/sadness/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two Hussein allies are hanged, Iraqi official ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trucks swallowed in subway collapse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Building a memorial to a son, one child at a time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetic waits months for eyeglasses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7 dead in apartment building fire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174006</th>\n",
       "      <td>Good news</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174007</th>\n",
       "      <td>@bigbadcraig20 @sirakashshah tell me about it....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174008</th>\n",
       "      <td>So much love for the psychosocial video. Love ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174020</th>\n",
       "      <td>just ate my last cookie from momofuku milk bar.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174039</th>\n",
       "      <td>oh wow this is a first...the popup ad that I w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15193 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "1       Two Hussein allies are hanged, Iraqi official ...      1\n",
       "5                     Trucks swallowed in subway collapse      1\n",
       "7       Building a memorial to a son, one child at a time      1\n",
       "9                    Diabetic waits months for eyeglasses      1\n",
       "18                      7 dead in apartment building fire      1\n",
       "...                                                   ...    ...\n",
       "174006                                          Good news      1\n",
       "174007  @bigbadcraig20 @sirakashshah tell me about it....      1\n",
       "174008  So much love for the psychosocial video. Love ...      1\n",
       "174020    just ate my last cookie from momofuku milk bar.      1\n",
       "174039  oh wow this is a first...the popup ad that I w...      1\n",
       "\n",
       "[15193 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oh wow this is a first...the popup ad that I was actually interested in reading disappeared without me clicking it.. #advertising'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[174039]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
